# ğŸ® CS7642 â€“ Lecture 11A-B-C: Game Theory

---

## ğŸ¤” What Is Game Theory?

- Game Theory is the mathematics of **conflicting interests** in decision-making.
- It becomes relevant in **multi-agent environments**.
- Agents must reason about the decisions of others to act optimally.

---

## ğŸ² A Simple Game

- Two agents, **A** and **B**, take alternating actions.
- The game is a **2-player, zero-sum, finite deterministic game with perfect information**.
- Rewards:
  - When A gains reward \( r \), B gets \( -r \).
- **Strategy** in Game Theory â‰ˆ **Policy** in MDPs:
  - A strategy maps **all possible states** to actions.

### ğŸ“Š Matrix Representation

- The game can be summarized in a matrix of strategies (A vs B).
- Each cell shows the outcome for a given strategy pair.

---

## â™Ÿï¸ Minimax Principle

- A and B aim to **minimize the other's maximum gain**.
- **Minimax Algorithm**:
  - A chooses the **max of minimums**.
  - B chooses the **min of maximums**.

### âœ… Key Result

- In 2-player, zero-sum, perfect-information games:
  \[
  \text{Minimax} = \text{Maximin}
  \]
- There always exists an **optimal pure strategy**.

---

## ğŸŒ² Game Tree Extensions

### 1. Non-deterministic Game

- Some game states behave **stochastically** (random transitions).

### 2. Minipoker

- **Hidden information + stochasticity**.
- A receives a red (bad) or black (good) card (50% chance).
  - Red â†’ Resign: A loses 20Â¢
  - Else hold:
    - B resigns â†’ A gains 10Â¢
    - B sees card:
      - Red â†’ A loses 40Â¢
      - Black â†’ A gains 30Â¢

---

## ğŸ² Mixed Strategies

- Instead of a fixed (pure) decision, use **probabilities** over strategies.
- Analyzed by treating one player as deterministic and the other probabilistic.
- **Maximin over outcome functions** determines value of the game.

---

## ğŸš¨ The Snitch (Prisonerâ€™s Dilemma)

- Two players choose to **Cooperate (C)** or **Defect (D)**.
- Best joint outcome: **both cooperate**
- Rational choice: **always defect**
  - Leads to **worse joint outcome** â†’ (-6, -6)

---

## ğŸ¯ Nash Equilibrium

A strategy profile 
$$ s^* = (s_1^*, s_2^*, \dots, s_n^*) $$ 
is a **Nash Equilibrium** if:

$$
s_i^* = \arg\max_{s_i} \text{Utility}_i(s_1^*, \dots, s_i, \dots, s_n^*)
$$

- No player has incentive to unilaterally change their strategy.
- Applies to **pure and mixed** strategies.

### ğŸ“š Theorems

1. If strict dominance eliminates all but one strategy combo â†’ it is the Nash Equilibrium.
2. Any Nash Equilibrium **survives strict dominance elimination**.
3. In any finite game â†’ **at least one Nash Equilibrium exists**.

---

## ğŸ‘£ The Two-Step & Iterated Prisonerâ€™s Dilemma (IPD)

### ğŸ”„ Finite Repetition:

- Backward induction â†’ always defect in final step.
- Therefore, rational strategy = **defect in all steps**.

### â“ What if number of rounds is **unknown**?

- Let continuation probability = \( \gamma \)
- Expected number of rounds:
  $$
  \frac{1}{1 - \gamma}
  $$
- Behaves like a **discount factor**.

### ğŸ¤ Tit-for-Tat (TFT)

- Cooperate first, then copy opponentâ€™s last move.

#### ğŸ“ˆ Strategy Payoffs:

| Strategy | Total Reward |
|----------|--------------|
| Always Defect | $$ \frac{-6\gamma}{1 - \gamma} $$ |
| Always Cooperate | $$ \frac{-1}{1 - \gamma} $$ |

Equate both:
\[
\frac{-6\gamma}{1 - \gamma} = \frac{-1}{1 - \gamma} \Rightarrow \gamma = \frac{1}{6}
\]

---

## ğŸ§  Best Response to Finite-State Strategy

- In multi-round games, actions affect **future reactions**.
- Use a **state machine**
